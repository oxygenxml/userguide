<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="cf-projects-publishing-metrics">
  <title>Publishing Metrics</title>
  <body>
    <p>The <uicontrol>Metrics</uicontrol> page provides insights into the performance and resource
      usage of your project's deliverables. It provides detailed data for your project's deliverable
      activities over the last 30 days. The page is organized into several sections, including a
      summary of the deliverables and detailed metrics for runs, queue times, durations, and disk
        requirements.<note id="note_kbm_c5g_tcc">To adjust the number of days that metrics are
        recorded, an administrator can set the
          <codeph>executor.service.metrics.disk.store.time</codeph> property for the Task Executor
        container. This property determines the length of the time window for which metrics data is
        stored and displayed.</note></p>
    <section id="section_py3_yrg_tcc">
      <title>Deliverables Summary</title>
      <p>
        <ul id="ul_aln_gsg_tcc">
          <li><uicontrol>Total Runs</uicontrol> - The total number of times the deliverable builds
            have been executed for a project within the last 30 days.</li>
          <li><uicontrol>Queued P50</uicontrol> - The 50th percentile of time that builds spend in a
            queue, meaning 50% of the builds waited in the queue for this amount of time or
            less.</li>
          <li><uicontrol>Duration P50</uicontrol> - The 50th percentile of the total duration of
            builds, meaning 50% of the builds completed within this time or less.</li>
          <li><uicontrol>Used Disk Space</uicontrol> - The total disk space consumed by artifacts
            (build outputs) and repositories.</li>
        </ul>
      </p>
    </section>
    <section id="section_kxh_hsg_tcc">
      <title>Deliverables Metrics</title>
      <p><b><u>Runs:</u></b><ul id="ul_alf_jsg_tcc">
          <li><uicontrol>Successful</uicontrol> - The number of deliverable builds that completed
            without errors.</li>
          <li><uicontrol>Failed</uicontrol> - The number of deliverable builds that did not complete
            successfully due to errors.</li>
          <li><uicontrol>Memory issues</uicontrol> - The number of deliverable builds that failed
            due to 'Out of Memory' errors.<note id="note_olp_m1v_tcc">If you encounter memory
              issues, contact your platform administrator to increase the memory allocated for the
              Task Executor container and OPE. This ensures there are sufficient resources for
              processing tasks. The OPE memory can be adjusted using the
                <codeph>executor.service.ope.max.memory</codeph> property.</note></li>
          <li><uicontrol>Success Rate</uicontrol> - The percentage of deliverable builds that were
            successful out of the total attempted runs.</li>
        </ul></p>
      <p><b><u>Queued:</u></b><ul id="ul_xxw_lsg_tcc">
          <li><uicontrol>Min</uicontrol> - The shortest time spent for a deliverable build in the
            queue.</li>
          <li><uicontrol>Max</uicontrol> - The longest time spent for a deliverable build in the
            queue.</li>
          <li><uicontrol>Average</uicontrol> - The average time spent for a deliverable build in the
            queue, calculated across all runs.</li>
          <li><uicontrol>P90</uicontrol> - The 90th percentile of time that deliverable builds spent
            in the queue, meaning 90% of the builds waited in the queue for this amount of time or
              less.<note id="note_ubc_xbv_tcc">If the <uicontrol>Average</uicontrol> or
                <uicontrol>P90</uicontrol> metrics are too high, the platform administrator may
              reduce the queue time by increasing the number of parallel builds using the
                <codeph>executor.service.parallel.publishing.builds</codeph> property.</note></li>
        </ul></p>
      <p><b><u>Duration:</u></b><ul id="ul_r1j_nsg_tcc">
          <li><uicontrol>Min</uicontrol> - The shortest time taken to build a deliverable.</li>
          <li><uicontrol>Max</uicontrol> - The longest time taken to build a deliverable.</li>
          <li><uicontrol>Average</uicontrol> - The average time taken to build a deliverable,
            calculated across all runs.</li>
          <li><uicontrol>P90</uicontrol> - The 90th percentile of time taken to build a deliverable,
            meaning 90% of the runs completed in this time or less.</li>
        </ul></p>
      <p><b><u>Disk Requirements:</u></b><ul id="ul_ntx_4sg_tcc">
          <li><uicontrol>Repository Clones Size</uicontrol> - The total disk space used by the
            repositories.</li>
          <li><uicontrol>Artifacts Size</uicontrol> - The total size of all artifacts (build
            outputs) generated by the deliverables.</li>
        </ul></p>
    </section>
    <section id="section_yh1_rsg_tcc">
      <title>Utilizing Metrics Data</title>
      <p>The metrics provided can help you:</p>
      <ul id="ul_pp4_rsg_tcc">
        <li>Monitor performance trends and identify potential bottlenecks.</li>
        <li>Assess the reliability of your deliverable runs via success rates and failure
          counts.</li>
        <li>Make data-driven decisions to streamline your publishing process.</li>
      </ul>
    </section>
  </body>
</topic>
